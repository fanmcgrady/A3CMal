diff --git a/requirements.txt b/requirements.txt
index 890b9aa..62b55ab 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -7,4 +7,5 @@ xgboost
 matplotlib
 IPython
 mahotas
-capstone
\ No newline at end of file
+capstone
+chainerrl
\ No newline at end of file
diff --git a/src/rl/A3C.py b/src/rl/A3C.py
index e69de29..5972984 100644
--- a/src/rl/A3C.py
+++ b/src/rl/A3C.py
@@ -0,0 +1,199 @@
+"""An example of training A3C against OpenAI Gym Envs.
+This script is an example of training a A3C agent against OpenAI Gym envs.
+Both discrete and continuous action spaces are supported.
+To solve CartPole-v0, run:
+    python train_a3c_gym.py 8 --env CartPole-v0
+To solve InvertedPendulum-v1, run:
+    python train_a3c_gym.py 8 --env InvertedPendulum-v1 --arch LSTMGaussian --t-max 50  # noqa
+"""
+import argparse
+import os
+
+# This prevents numpy from using multiple threads
+os.environ['OMP_NUM_THREADS'] = '1'  # NOQA
+
+import chainer
+from chainer import functions as F
+from chainer import links as L
+import gym
+import numpy as np
+
+import chainerrl
+from chainerrl.agents import a3c
+from chainerrl import experiments
+from chainerrl import links
+from chainerrl import misc
+from chainerrl.optimizers.nonbias_weight_decay import NonbiasWeightDecay
+from chainerrl.optimizers import rmsprop_async
+from chainerrl import policies
+from chainerrl.recurrent import RecurrentChainMixin
+from chainerrl import v_function
+
+
+class A3CFFSoftmax(chainer.ChainList, a3c.A3CModel):
+    """An example of A3C feedforward softmax policy."""
+
+    def __init__(self, ndim_obs, n_actions, hidden_sizes=(200, 200)):
+        self.pi = policies.SoftmaxPolicy(
+            model=links.MLP(ndim_obs, n_actions, hidden_sizes))
+        self.v = links.MLP(ndim_obs, 1, hidden_sizes=hidden_sizes)
+        super().__init__(self.pi, self.v)
+
+    def pi_and_v(self, state):
+        return self.pi(state), self.v(state)
+
+
+class A3CFFMellowmax(chainer.ChainList, a3c.A3CModel):
+    """An example of A3C feedforward mellowmax policy."""
+
+    def __init__(self, ndim_obs, n_actions, hidden_sizes=(200, 200)):
+        self.pi = policies.MellowmaxPolicy(
+            model=links.MLP(ndim_obs, n_actions, hidden_sizes))
+        self.v = links.MLP(ndim_obs, 1, hidden_sizes=hidden_sizes)
+        super().__init__(self.pi, self.v)
+
+    def pi_and_v(self, state):
+        return self.pi(state), self.v(state)
+
+
+class A3CLSTMGaussian(chainer.ChainList, a3c.A3CModel, RecurrentChainMixin):
+    """An example of A3C recurrent Gaussian policy."""
+
+    def __init__(self, obs_size, action_size, hidden_size=200, lstm_size=128):
+        self.pi_head = L.Linear(obs_size, hidden_size)
+        self.v_head = L.Linear(obs_size, hidden_size)
+        self.pi_lstm = L.LSTM(hidden_size, lstm_size)
+        self.v_lstm = L.LSTM(hidden_size, lstm_size)
+        self.pi = policies.FCGaussianPolicy(lstm_size, action_size)
+        self.v = v_function.FCVFunction(lstm_size)
+        super().__init__(self.pi_head, self.v_head,
+                         self.pi_lstm, self.v_lstm, self.pi, self.v)
+
+    def pi_and_v(self, state):
+
+        def forward(head, lstm, tail):
+            h = F.relu(head(state))
+            h = lstm(h)
+            return tail(h)
+
+        pout = forward(self.pi_head, self.pi_lstm, self.pi)
+        vout = forward(self.v_head, self.v_lstm, self.v)
+
+        return pout, vout
+
+
+def main():
+    import logging
+
+    parser = argparse.ArgumentParser()
+    parser.add_argument('processes', type=int)
+    parser.add_argument('--env', type=str, default='CartPole-v0')
+    parser.add_argument('--arch', type=str, default='FFSoftmax',
+                        choices=('FFSoftmax', 'FFMellowmax', 'LSTMGaussian'))
+    parser.add_argument('--seed', type=int, default=0,
+                        help='Random seed [0, 2 ** 32)')
+    parser.add_argument('--outdir', type=str, default='results',
+                        help='Directory path to save output files.'
+                             ' If it does not exist, it will be created.')
+    parser.add_argument('--t-max', type=int, default=5)
+    parser.add_argument('--beta', type=float, default=1e-2)
+    parser.add_argument('--profile', action='store_true')
+    parser.add_argument('--steps', type=int, default=8 * 10 ** 7)
+    parser.add_argument('--eval-interval', type=int, default=10 ** 5)
+    parser.add_argument('--eval-n-runs', type=int, default=10)
+    parser.add_argument('--reward-scale-factor', type=float, default=1e-2)
+    parser.add_argument('--rmsprop-epsilon', type=float, default=1e-1)
+    parser.add_argument('--render', action='store_true', default=False)
+    parser.add_argument('--lr', type=float, default=7e-4)
+    parser.add_argument('--weight-decay', type=float, default=0.0)
+    parser.add_argument('--demo', action='store_true', default=False)
+    parser.add_argument('--load', type=str, default='')
+    parser.add_argument('--logger-level', type=int, default=logging.DEBUG)
+    parser.add_argument('--monitor', action='store_true')
+    args = parser.parse_args()
+
+    logging.basicConfig(level=args.logger_level)
+
+    # Set a random seed used in ChainerRL.
+    # If you use more than one processes, the results will be no longer
+    # deterministic even with the same random seed.
+    misc.set_random_seed(args.seed)
+
+    # Set different random seeds for different subprocesses.
+    # If seed=0 and processes=4, subprocess seeds are [0, 1, 2, 3].
+    # If seed=1 and processes=4, subprocess seeds are [4, 5, 6, 7].
+    process_seeds = np.arange(args.processes) + args.seed * args.processes
+    assert process_seeds.max() < 2 ** 32
+
+    args.outdir = experiments.prepare_output_dir(args, args.outdir)
+
+    def make_env(process_idx, test):
+        env = gym.make(args.env)
+        # Use different random seeds for train and test envs
+        process_seed = int(process_seeds[process_idx])
+        env_seed = 2 ** 32 - 1 - process_seed if test else process_seed
+        env.seed(env_seed)
+        # Cast observations to float32 because our model uses float32
+        env = chainerrl.wrappers.CastObservationToFloat32(env)
+        if args.monitor and process_idx == 0:
+            env = chainerrl.wrappers.Monitor(env, args.outdir)
+        if not test:
+            # Scale rewards (and thus returns) to a reasonable range so that
+            # training is easier
+            env = chainerrl.wrappers.ScaleReward(env, args.reward_scale_factor)
+        if args.render and process_idx == 0 and not test:
+            env = chainerrl.wrappers.Render(env)
+        return env
+
+    sample_env = gym.make(args.env)
+    timestep_limit = sample_env.spec.max_episode_steps
+    obs_space = sample_env.observation_space
+    action_space = sample_env.action_space
+
+    # Switch policy types accordingly to action space types
+    if args.arch == 'LSTMGaussian':
+        model = A3CLSTMGaussian(obs_space.low.size, action_space.low.size)
+    elif args.arch == 'FFSoftmax':
+        model = A3CFFSoftmax(obs_space.low.size, action_space.n)
+    elif args.arch == 'FFMellowmax':
+        model = A3CFFMellowmax(obs_space.low.size, action_space.n)
+
+    opt = rmsprop_async.RMSpropAsync(
+        lr=args.lr, eps=args.rmsprop_epsilon, alpha=0.99)
+    opt.setup(model)
+    opt.add_hook(chainer.optimizer.GradientClipping(40))
+    if args.weight_decay > 0:
+        opt.add_hook(NonbiasWeightDecay(args.weight_decay))
+
+    agent = a3c.A3C(model, opt, t_max=args.t_max, gamma=0.99,
+                    beta=args.beta)
+    if args.load:
+        agent.load(args.load)
+
+    if args.demo:
+        env = make_env(0, True)
+        eval_stats = experiments.eval_performance(
+            env=env,
+            agent=agent,
+            n_steps=None,
+            n_episodes=args.eval_n_runs,
+            max_episode_len=timestep_limit)
+        print('n_runs: {} mean: {} median: {} stdev {}'.format(
+            args.eval_n_runs, eval_stats['mean'], eval_stats['median'],
+            eval_stats['stdev']))
+    else:
+        experiments.train_agent_async(
+            agent=agent,
+            outdir=args.outdir,
+            processes=args.processes,
+            make_env=make_env,
+            profile=args.profile,
+            steps=args.steps,
+            eval_n_steps=None,
+            eval_n_episodes=args.eval_n_runs,
+            eval_interval=args.eval_interval,
+            max_episode_len=timestep_limit)
+
+
+if __name__ == '__main__':
+    main()
\ No newline at end of file
diff --git a/src/test/test.py b/src/test/test.py
index b915844..f7871c4 100644
--- a/src/test/test.py
+++ b/src/test/test.py
@@ -1,22 +1,41 @@
-from capstone import *
-from decompiler import *
-from host import dis
-from output import c
+import numpy as np
+from sklearn.metrics import accuracy_score
 
-# Create a Capstone object, which will be used as disassembler
-md = Cs(CS_ARCH_X86, CS_MODE_32)
 
-# Define a bunch of bytes to disassemble
-code = "\x55\x89\xe5\x83\xec\x28\xc7\x45\xf4\x00\x00\x00\x00\x8b\x45\xf4\x8b\x00\x83\xf8\x0e\x75\x0c\xc7\x04\x24\x30\x87\x04\x08\xe8\xd3\xfe\xff\xff\xb8\x00\x00\x00\x00\xc9\xc3"
+def GenerateData(num):
+    data = []
+    label = []
+    t = np.random.random(size=num) * 2 * np.pi - np.pi
+    x = np.cos(t)
+    y = np.sin(t)
+    for i in range(0, num):
+        len = np.sqrt(np.random.random()) * 10
+        dx = x[i] * len
+        dy = y[i] * len
+        if len < 8:
+            label.append(1)
+        else:
+            label.append(0)
+        data.append([dx, dy])
+    return (data, label)
 
-# Create the capstone-specific backend; it will yield expressions that the decompiler is able to use.
-disasm = dis.available_disassemblers['capstone'].create(md, code, 0x1000)
 
-# Create the decompiler
-dec = decompiler_t(disasm, 0x1000)
+num = 40000
+train = int(num * 0.8)
+(x_train, y_train) = GenerateData(num)
+x_train_norm = np.array(x_train[:train])
+x_test_norm = np.array(x_train[train:])
+x_train_norm = x_train_norm / 10
+x_test_norm = x_test_norm / 10
+y_trains = np.array(y_train[:train])
+y_tests = np.array(y_train[train:])
 
-# Transform the function until it is decompiled
-dec.step_until(step_decompiled)
+import xgboost_multi
 
-# Tokenize and output the function as string
-print(''.join([str(o) for o in c.tokenizer(dec.function).tokens]))
\ No newline at end of file
+model = xgboost_multi.XGBC()
+model.fit(x_train_norm, y_trains)
+y_pre = model.predict_proba(x_test_norm)
+print(y_pre)
+# 评估预测结果
+accuracy = accuracy_score(y_tests, y_pre)
+print("Accuracy: %.2f%%" % (accuracy * 100.0))
\ No newline at end of file
