# encoding=utf-8
import csv
import hashlib
import os
import random
from collections import OrderedDict

import gym
from gym import spaces

from action import action as manipulate
from tools.interface import *

ACTION_LOOKUP = {i: act for i, act in enumerate(
    manipulate.ACTION_TABLE.keys())}

# change this to function to the AV engine to attack
# function should be of the form
# def label_function( bytez ):
#    # returns 0.0 if benign else 1.0 if malware

# an environment must define its
# observation space and action space
# and have at least two methods: reset and step.

# * env.reset will reset the environment to the initial state and return the initial observation.
# * env.step will execute a given action, move to the next state and return four values:
#   a next observation
#   a scalar reward
#   a boolean value indicating whether the current state is terminal or not
#   additional information
# * env.render will render the current state.
# class MalwareEnv():
class MalwareEnv(gym.Env):
    metadata = {'render.modes': ['human']}

    def __init__(self, sha256list, random_sample=True, maxturns=60, cache=True,
                 test=False):
        self.test = test
        print("[Using env {}]".format('malware-test-v0' if self.test else 'malware-v0'))
        self.interface = Interface(test=self.test)
        self.label_function = self.interface.get_label_local

        self.total_turn = 0  # 总共累计修改
        self.test_turn = 0  #
        self.episode = -1  # 共训练了多少轮
        self.cache = cache  # 是否把所有pe样本缓存进内存，默认True
        self.available_sha256 = sha256list  # pe文件列表
        self.action_space = spaces.Discrete(len(ACTION_LOOKUP))
        self.maxturns = maxturns
        self.random_sample = random_sample
        self.sample_iteration_index = 0

        self.original_path = os.path.join(
            os.path.dirname(
                os.path.dirname(
                    os.path.dirname(
                        os.path.abspath(__file__)))), "../../Dataset/original")
        self.modification_path = os.path.join(
            os.path.dirname(
                os.path.dirname(
                    os.path.dirname(
                        os.path.abspath(__file__)))), "../../Dataset/modification/")

        self.samples_path = os.path.join(
            os.path.dirname(
                os.path.dirname(
                    os.path.dirname(
                        os.path.abspath(__file__)))), "../../Dataset/")

        self.history = OrderedDict()
        self.current_reward = 0

        self.samples = {}



        if self.cache:
            for i, sha256 in enumerate(self.available_sha256):
                # print("{}:Cache samples [{}]".format(i + 1, sha256))
                try:
                    self.samples[sha256] = self.interface.fetch_file(sha256)
                    # self.samples[sha256] = interface.fetch_file(sha256, self.test)
                except:
                    print("failed fetching file{}".format(sha256))
                    continue  # try a new sha256...this one can't be retrieved from storage

        # 读出trainLabel.csv，获得原始标签
        self.label_map = self.interface.get_original_label()

        self.reset()

    def step(self, action_index):
        self.total_turn += 1
        self.turns += 1
        self._take_action(action_index)  # update self.bytez
        # get reward
        try:
            self.label, self.observation_space = self.label_function(self.bytez)
        except:
            print("Failed to classify file {}".format(self.sha256))
            episode_over = True
        else:
            # non-targeted
            # if self.label != self.label_map[self.sha256]:
            # targeted
            if int(self.label) == (int(self.label_map[self.sha256]) + 1) % 9:
                # we win!
                # self.current_reward = 10 - (self.turns - 1) * 10 / self.maxturns  # !! a strong reward
                self.current_reward = 10  # !! a strong reward
                # reward = 10
                episode_over = True
                self.history[self.sha256]['evaded'] = True
                print("Success:{}:{}".format(self.sha256, self.history[self.sha256]['actions']))

                # store sample to output directory
                # if self.test:
                #     m = hashlib.sha256()
                #     m.update(self.bytez)
                #     sha256 = m.hexdigest()
                #     self.history[self.sha256]['evaded_sha256'] = sha256

                    # with open(os.path.join(self.modification_path, str(self.sample_iteration_index - 2) + self.sha256),
                    #           'wb') as outfile:
                    #     outfile.write(self.bytez)


            elif self.turns >= self.maxturns:
                # out of turns :(
                self.current_reward = 0.0
                episode_over = True
                print("Failure:{}:{}".format(self.sha256, self.history[self.sha256]['actions']))
            else:
                self.current_reward = 0.0
                episode_over = False

        # if episode_over:
        #     print("episode is over: reward = {}!".format(reward))

        return self.observation_space, self.current_reward, episode_over, {}

    def _take_action(self, action_index):
        assert action_index < len(ACTION_LOOKUP)
        action = ACTION_LOOKUP[action_index]
        # print("[{}:Taking action {}]".format(self.turns, action))
        self.history[self.sha256]['actions'].append(action)
        self.bytez = bytes(manipulate.modify_without_breaking(self.bytez, action))

        # print("turns {} : {}".format(self.turns, action))

    def reset(self):
        self.turns = 0
        self.episode += 1
        while True:
            # get the new environment
            if self.random_sample:
                self.sha256 = random.choice(self.available_sha256)
            else:  # draw a sample at random
                self.sha256 = self.available_sha256[self.sample_iteration_index % len(self.available_sha256)]
                self.sample_iteration_index += 1

            self.history[self.sha256] = {'actions': [], 'evaded': False}

            if self.cache:
                self.bytez = self.samples[self.sha256]
            else:
                try:
                    self.bytez = self.interface.fetch_file(self.sha256)
                except:
                    print("failed fetching file{}".format(self.sha256))
                    continue  # try a new sha256...this one can't be retrieved from storage

            # TODO: 这里没看懂
            # if self.test and self.episode > 0:
            #     with open(os.path.join(self.original_path, str(self.sample_iteration_index - 2) + self.sha256),
            #               'wb') as outfile:
            #         outfile.write(self.bytez)

            predict_label, self.observation_space = self.label_function(self.bytez)
            if predict_label != self.label_map[self.sha256]:
                # skip this one, it's misclassified, and the agent will learn nothing
                continue

            self.tips = ' ' if not self.test else 'test '

            if self.episode > 0:
                print("--------------------------------------------------------------------------------")
                print("{}episode {} select training sample: {}".format(self.tips, self.episode, self.sha256))
                print("--------------------------------------------------------------------------------")

            break  # we're done here

        return self.observation_space

    def render(self, mode='human', close=False):
        pass
